{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb1517c",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4f5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afd34f",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c5a88",
   "metadata": {},
   "source": [
    "### spit evaluate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6774929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('./raw_data/train.tsv', sep='\\t')\n",
    "df_data.info()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d410fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(len(df_data))\n",
    "shuffled_data = df_data[['Phrase','Sentiment']].iloc[shuffle_index]\n",
    "shuffled_data.iloc[:int(0.7*len(df_data))].to_csv(r'./data_set/train.txt', sep='\\t', encoding='utf-8', header=None)\n",
    "shuffled_data.iloc[int(0.7*len(df_data))+1:int(0.9*len(df_data))].to_csv(r'./data_set/dev.txt', sep='\\t', encoding='utf-8', header=None)\n",
    "shuffled_data.iloc[int(0.9*len(df_data))+1:].to_csv(r'./data_set/test.txt', sep='\\t', encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d192ecc",
   "metadata": {},
   "source": [
    "### build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42cabbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df68b7ac16a46d58ac6c8f745016fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156060 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# 获取单词的词性\n",
    "def get_wordnet_pos(tag):\n",
    "    '''\n",
    "    for WordNetLemmatizer.lemmatize()\n",
    "    '''\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# sentence = 'football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.'\n",
    "\n",
    "word_cnt = dict() # 同时统计一下词频\n",
    "for sentence in tqdm(all_data['Phrase']):\n",
    "    tokens = word_tokenize(sentence.lower())              # 分词,同时大写换小写\n",
    "    tagged_sent = pos_tag(tokens, tagset='universal')     # 词性标注\n",
    "    wnl = WordNetLemmatizer()\n",
    "#     lemmas_sent = []\n",
    "    for word, tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "        lemmatized_word = wnl.lemmatize(word, pos=wordnet_pos) # 还原后的词\n",
    "        if lemmatized_word in word_cnt:\n",
    "            word_cnt[lemmatized_word] += 1\n",
    "        else:\n",
    "            word_cnt[lemmatized_word] = 1\n",
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2498e90b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14755"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_cnt)\n",
    "with open(r'./data_set/vocabulary.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in word_cnt.keys():\n",
    "        word_num = f.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebc4ae",
   "metadata": {},
   "source": [
    "### limit vocab size version(process unknown word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcaa731",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86086806",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = r'./data_set/vocabulary.txt'\n",
    "vocab = open(vocab_path).readlines()\n",
    "\n",
    "def get_one_hot_vector(sent, vocab):\n",
    "    sent = all_data['Phrase'][10005] # test\n",
    "    tokens = word_tokenize(sent.lower())\n",
    "    tagged_sent = pos_tag(tokens, tagset='universal')     # 词性标注\n",
    "    lemmatized_words = list()\n",
    "    for word, tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "        lemmatized_words.append(wnl.lemmatize(word, pos=wordnet_pos))\n",
    "    ind = np.zeros(len(vocab), dtype=int)\n",
    "    for word in lemmatized_words:\n",
    "        ind[vocab.index(word)] = 1 # Raises ValueError if the value is not present. \n",
    "    return ind\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a159b8",
   "metadata": {},
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48938037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config(object):\n",
    "    def __init__(self, vocab_path):\n",
    "        self.vocab = vocab_path\n",
    "        self.train_path = r'./data_set/train.txt'\n",
    "        self.train_path = r'./data_set/dev.txt'\n",
    "        self.train_path = r'./data_set/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596b345",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEmbedding(object):\n",
    "    def __init__(self, config):\n",
    "        vocab = open(config.vocab_path).readlines()\n",
    "        \n",
    "        \n",
    "    def batch_vectorize(self,x):\n",
    "        '''\n",
    "        '''\n",
    "        def get_one_hot_vector(self, sent, vocab):\n",
    "            sent = all_data['Phrase'][10005] # test\n",
    "            tokens = word_tokenize(sent.lower())\n",
    "            tagged_sent = pos_tag(tokens, tagset='universal')     # 词性标注\n",
    "            lemmatized_words = list()\n",
    "            for word, tag in tagged_sent:\n",
    "                wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "                lemmatized_words.append(wnl.lemmatize(word, pos=wordnet_pos))\n",
    "            ind = np.zeros(len(vocab), dtype=int)\n",
    "            for word in lemmatized_words:\n",
    "                ind[vocab.index(word)] = 1 # Raises ValueError if the value is not present. \n",
    "            return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018c48a",
   "metadata": {},
   "source": [
    "DatasetIterater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b5ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterater(object):\n",
    "    '''\n",
    "    return the batch index of dataset\n",
    "    '''\n",
    "    def __init__(self, data_set, batch_size):\n",
    "        self.data_set = data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = len(data_set) // batch_size\n",
    "#         self.residue = False  # 记录batch数量是否为整数\n",
    "#         if len(batches) % self.n_batches != 0:\n",
    "#             self.residue = True\n",
    "        self.residue = True if len(data_set) % self.n_batches != 0 else False\n",
    "        self.index = 0\n",
    "        \n",
    "    def to_couple(self, data_slice):\n",
    "        x = list()\n",
    "        x = [_[0] for _ in data_slice]\n",
    "        x = [_[0] for _ in data_slice]\n",
    "        return \n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.index == self.n_batches and self.residue:\n",
    "            batch = self.data_set[self.index * self.batch_size: len(data_set)]\n",
    "            self.index += 1\n",
    "            return batch\n",
    "        elif self.index >= self.n_batches:\n",
    "            self.index = 0\n",
    "            return StopIteration\n",
    "        else:\n",
    "            batch = self.data_set[self.index * self.batch_size: (self.index+1) * self.batch_size]\n",
    "            self.index += 1\n",
    "            return batch\n",
    "           \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches+1 if self.residue else self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a467ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = DatasetIterater(data_set = df_data[['Phrase', 'Sentiment']], batch_size = 4)\n",
    "df_test = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d49ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       " 'A series of escapades demonstrating the adage that what is good for the goose',\n",
       " 'A series',\n",
       " 'A']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "325e901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30595c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros(10, int)\n",
    "z[[2,1,3]] = 1\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b0b78",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53384bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bb31942",
   "metadata": {},
   "source": [
    "## train and eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
