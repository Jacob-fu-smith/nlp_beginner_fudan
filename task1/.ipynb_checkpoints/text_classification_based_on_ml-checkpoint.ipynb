{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4f5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afd34f",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6774929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('./data_set/train.tsv', sep='\\t')\n",
    "all_data.info()\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d192ecc",
   "metadata": {},
   "source": [
    "### build word vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42cabbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df68b7ac16a46d58ac6c8f745016fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156060 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# 获取单词的词性\n",
    "def get_wordnet_pos(tag):\n",
    "    '''\n",
    "    for WordNetLemmatizer.lemmatize()\n",
    "    '''\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# sentence = 'football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.'\n",
    "\n",
    "word_cnt = dict() # 同时统计一下词频\n",
    "for sentence in tqdm(all_data['Phrase']):\n",
    "    tokens = word_tokenize(sentence.lower())              # 分词,同时大写换小写\n",
    "    tagged_sent = pos_tag(tokens, tagset='universal')     # 词性标注\n",
    "    wnl = WordNetLemmatizer()\n",
    "#     lemmas_sent = []\n",
    "    for word, tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "        lemmatized_word = wnl.lemmatize(word, pos=wordnet_pos) # 还原后的词\n",
    "        if lemmatized_word in word_cnt:\n",
    "            word_cnt[lemmatized_word] += 1\n",
    "        else:\n",
    "            word_cnt[lemmatized_word] = 1\n",
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3e810a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14755"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_cnt)\n",
    "with open(r'./output/vocabulary.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in word_cnt.keys():\n",
    "        word_num = f.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcaa731",
   "metadata": {},
   "source": [
    "### word vecotorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86086806",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(word_cnt.keys())\n",
    "\n",
    "def get_one_hot_vector(sent, vocab_size):\n",
    "    sent = all_data['Phrase'][10005]\n",
    "    tokens = word_tokenize(sent.lower())\n",
    "    tagged_sent = pos_tag(tokens, tagset='universal')     # 词性标注\n",
    "    lemmatized_words = list()\n",
    "    for word, tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "        lemmatized_words.append(wnl.lemmatize(word, pos=wordnet_pos))\n",
    "    ind = np.zeros(vocab_size, dtype=int)\n",
    "    for word in lemmatized_words:\n",
    "        ind[vocab.index(word)] = 1 # Raises ValueError if the value is not present. \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "673c0fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros(10, int)\n",
    "z[[2,1,3]] = 1\n",
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
